# Machine-Learning-Speech-Emotion-Recognition

## Project Overview
Developed by Jon Karakus, this repository is part of a larger project focused on machine learning and speech emotion recognition. It showcases the use of Support Vector Machines (SVM) and Cross Validation to analyze audio samples and recognize emotional states from speech. The sample code shared here demonstrates the methodologies and machine learning techniques employed in achieving speech emotion recognition.

## Note
This codebase is shared as a sample of my machine learning expertise, in the domain of audio processing and emotion recognition.

## Key Achievements
- Achieved an 80% f-score accuracy across four emotions: angry, happy, neutral, and sad.


## Methodology
- **Pre-processing**: High-pass and Low-pass filters applied to audio sample. 
- **Data Processing**: Audio samples were preprocessed to extract relevant features suitable for SVM training.
- **SVM Training**: Utilized Support Vector Machines for modeling emotional state recognition based on audio features.
- **Model Tuning**: Applied cross-validation methods to fine-tune the model parameters, optimizing for best performance.
- **Model Evaluation**: Classification report and User Interface for live demonstration purposes. 

## Usage
To use this code for your own speech emotion recognition tasks, clone the repository

```bash
git clone https://github.com/your-github-username/Machine-Learning-Speech-Emotion-Recognition.git
cd Machine-Learning-Speech-Emotion-Recognition
